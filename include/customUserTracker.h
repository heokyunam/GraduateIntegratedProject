#include <openni-nite/NiteCAPI.h>
#include <openni-nite/NiTE.h>
#include <openni-nite/NiteEnums.h>
#include <openni2/OpenNI.h>
#include <iostream>

using namespace nite;

/**
This is the main object of the User Tracker algorithm.  It provides access to one half of the
algorithms provided by NiTE.  Scene segmentation, skeleton, floor plane detection, and pose
detection are all provided by this class.

The first purpose of the User Tracker algorithm is to find all of the active users in a specific scene.
It individually tracks each human it finds, and provides the means to seperate their outline from
each other and from the background.  Once the scene has been segmented, the User Tracker is also used to initiate Skeleton
Tracking and Pose Detection algorithms.

Each user is provided an ID as they are detected.  The user ID remains constant as long as the
user remains in the frame.  If a user leaves the field of view of the camera, or tracking of that
user is otherwise lost, the user may have a different ID when he is detected again.  There is
currently no mechanism that provides persistant recognition of individuals when they are not being
actively tracking.  If this functionality is desired, it will need to be implimented at the
application level.

A listener class is provided to allow event based interaction with this algorithm.

@see UserMap for the output format of the User Tracker algorithm
@see UserData for additional data output by this format
@see Skeleton if you are also interested in tracking a user's skeleton
@see NiTE for a couple of static functions that must be run before User Tracker can be used
@see @ref HandTracker for Gesture and Hand tracking algorithms.
*/
class CustomUserTracker : public UserTracker
{
public:
	/**
	This is a listener class that is used to react to events generated by the @ref UserTracker class.

	To use this class, you must derive a class from it that implements the @ref onNewFrame() function.  This
	is the function that will be called when an event is generated.

	Create a new instance of your derived class.  Then, use the @ref UserTracker::addNewFrameListener()
	function to add the listener to the @ref UserTracker.  When that @ref UserTracker generates an onNewFrame event, \
	the specified callback function will be called.

	The onNewFrame event is currently the only event type that this listener is designed to work with.

	@see @ref UserTracker for the source of this listener's events.
	*/
	class NewFrameListener
	{
	public:
		/**
		Default Constructor.  Creates a new object of this type and configures it to correctly receive
		events.
		*/
		NewFrameListener() : m_pUserTracker(NULL)
		{
			m_userTrackerCallbacks.readyForNextFrame = newFrameCallback;
		}

		/**
		This is the callback function for the event.  It should be implemented in a class derived from NewFrameListener.
		This function will automatically be called when the OnNewFrame event is triggered.

		@param [in] A reference to the UserTracker that triggered the event is provided.
		*/
		virtual void onNewFrame(UserTracker&) = 0;

	private:
		NiteUserTrackerCallbacks m_userTrackerCallbacks;

		NiteUserTrackerCallbacks& getCallbacks() {return m_userTrackerCallbacks;}

		static void ONI_CALLBACK_TYPE newFrameCallback(void* pCookie)
		{
			NewFrameListener* pListener = (NewFrameListener*)pCookie;
			pListener->onNewFrame(*pListener->m_pUserTracker);
		}


		friend class UserTracker;
		void setUserTracker(UserTracker* pUserTracker)
		{
			m_pUserTracker = pUserTracker;
		}

		UserTracker* m_pUserTracker;
	};

	/**
	Default constructor.  Creates an empty @ref UserTracker with a NULL handle.  This object will not be useful
	until the @ref create() function is called.

	@see @ref UserTracker::create() for a function to create and activate the algorithm.
	@see @ref UserTracker::isValid() to determine whether @ref create() has already been called.
	*/
	CustomUserTracker() : m_userTrackerHandle(NULL)
	{}

	/**
	Destructor.  Automatically calls the provided @ref destroy() function.
	*/
	~CustomUserTracker()
	{
		destroy();
	}

	/**
	Creates and initializes an empty User Tracker.  This function should be the first one called when
	a new UserTracker object is constructed.

	An OpenNI device with depth capabilities is required for this algorithm to work.  See the OpenNI 2.0
	documentation for more information about using an OpenNI 2.0 compliant hardware device and creating
	a Device object.

	@param [in] pDevice A pointer to an initalized OpenNI 2.0 Device object that provides depth streams.
	@returns A status code to indicate success/failure.  Since this relies on an external hardware
	device, it is important for applications to check this value.

	@see Status enumeration for a list of all possible status values generated by this call.
	*/
	Status create(openni::Device* pDevice = NULL)
	{
		if (isValid())
		{
			// tracker already active
			return STATUS_OUT_OF_FLOW;
		}

		if (pDevice == NULL)
		{
			return (Status)niteInitializeUserTracker(&m_userTrackerHandle);
		}
		return (Status)niteInitializeUserTrackerByDevice(pDevice, &m_userTrackerHandle);
	}

	/**
	Shuts down the user tracker and releases all resources used by it.

	This is the opposite of create().  This function is called automatically
	by the destructor in the current implimentation, but it is good practice to run it manually when the algorithm
	is no longer required.  Running this function more than once is safe -- it simply exits if called on a
	non-valid UserTracker.
	*/
	void destroy()
	{
		if (isValid())
		{
			niteShutdownUserTracker(m_userTrackerHandle);
			m_userTrackerHandle = NULL;
		}
	}

	/**
	Gets the next snapshot of the algorithm.  This causes all data to be generated for the next frame of the
	algorithm -- algorithm frames correspond to the input depth frames used to generate them.OpenNI.h>

	@param pFrame [out] A pointer that will be set to point to the next frame of data.
	@returns Status code indicating whether this operation was successful.
	*/
	Status readFrame(UserTrackerFrameRef* pFrame)
	{
		NiteUserTrackerFrame *pNiteFrame = NULL;
		Status rc = (Status)niteReadUserTrackerFrame(m_userTrackerHandle, &pNiteFrame);
		pFrame->setReference(m_userTrackerHandle, pNiteFrame);
        
        std::cout << "CustomUserTracker readFrame called" << std::endl;
		return rc;
	}

	/**
	Indicates whether the UserTracker is valid.

	When a new UserTracker is first constructed, this function will indicate that it is invalid (ie return False).  Once
	the create() function has been successfully called, then this function will return True.  If the destroy() function
	is called, this function will again indicate invalid.

	It is safe to run create() and destroy() without calling this function -- both of those functions already check this
	value and return without doing anything if no action is required.

	@returns True if the UserTracker object is correctly initialized, False otherwise.

	@see create() function -- causes the UserTracker to become initialized.
	@see destroy() function -- causes the UserTracker to become uninitialized.
	*/
	bool isValid() const
	{
		return m_userTrackerHandle != NULL;
	}

	/**
	Control the smoothing factor of the skeleton joints. Factor should be between 0 (no smoothing at all) and 1 (no movement at all).

	Experimenting with this factor should allow you to fine tune the skeleton performance.  Higher values will produce smoother operation
	of the skeleton, but may make the skeleton feel less responsive to the user.

	@param [in] factor The smoothing factor.
	@returns Status code indicating success or failure of this operation.
	*/
	Status setSkeletonSmoothingFactor(float factor)
	{
		return (Status)niteSetSkeletonSmoothing(m_userTrackerHandle, factor);
	}

	/**
	Queries the current skeleton smoothing factor.

	@returns Current skeleton smoothing factor.

	@see setSkeletonSmoothingFactor for more information on the smoothing factor, and the means to change it.
	*/
	float getSkeletonSmoothingFactor() const
	{
		float factor;
		Status rc = (Status)niteGetSkeletonSmoothing(m_userTrackerHandle, &factor);
		if (rc != STATUS_OK)
		{
			factor = 0;
		}
		return factor;
	}

	/**
	Requests that the Skeleton algorithm starts tracking a specific user.  Once started, the skeleton will
	provide information on the joint position and orientation for that user during each new frame of the
	UserTracker.

	Note that the computational requirements of calculating a skeleton increase linearly with the number of
	users tracked.  Tracking too many users may result in poor performance and high CPU utilization.  If
	performance slows to the point where the skeleton is not calculated at the full frame rate of the depth
	data used to generate it, the algorithm tends to perform poorly.

	@param [in] UserID The ID number of the user to calculate a skeleton for.
	@returns Status code indicating success or failure of this operation.

	@see nite::Skeleton for more information on the skeleton algorithm.
	*/
	Status startSkeletonTracking(UserId id)
	{
		return (Status)niteStartSkeletonTracking(m_userTrackerHandle, id);
	}

	/**
	Stops skeleton tracking for a specific user.  If multiple users are being tracked, this will only stop
	tracking for the user specified -- skeleton calculation will continue for remaining users.

	@param [in] UserID of the person to stop tracking.

	@see nite::Skeleton for more information on the skeleton algorithm.
	*/
	void stopSkeletonTracking(UserId id)
	{
		niteStopSkeletonTracking(m_userTrackerHandle, id);
	}

	/**
	This function commands the @ref UserTracker to start detecting specific poses for a specific user.

	@param [in] user The @ref UserID of the user that you would like to detect a pose for.
	@param [in] type The type of pose you would like to detect.
	@returns @ref Status code indicating success or failure of this operation.

	@see @ref PoseData For more information on pose detection and the output it generates.
	@see @ref PoseType enumeration for a list of the available poses that can be detected.
	*/
	Status startPoseDetection(UserId user, PoseType type)
	{
		return (Status)niteStartPoseDetection(m_userTrackerHandle, (NiteUserId)user, (NitePoseType)type);
	}

	/**
	This function commands the pose detection algorithm to stop detecting a specific pose for a specific
	user.  Since it is possible to detect multiple poses from multiple users, it is possible that detection
	of a different pose on the same user (or the same pose on a different user) may continue after this function
	is called.

	@param [in] user The @ref UserID of the user to stop detecting a specific pose for.
	@param [in] type The @ref PoseType of the pose to stop detecting.
	*/
	void stopPoseDetection(UserId user, PoseType type)
	{
		niteStopPoseDetection(m_userTrackerHandle, (NiteUserId)user, (NitePoseType)type);
	}

	/**
	Adds a @ref NewFrameListner object to this @ref UserTracker so that it will respond when a new frame
	is generated.

	@param [in] pListener Pointer to a listener to add.

	@see @ref UserTracker::NewFrameListener for more information on using event based interaction with UserTracker
	*/
	void addNewFrameListener(NewFrameListener* pListener)
	{
		niteRegisterUserTrackerCallbacks(m_userTrackerHandle, &pListener->getCallbacks(), pListener);
		pListener->setUserTracker(this);
	}

	/**
	Removes a @ref NewFrameListener object from this UserTracker's list of listeners.  The listener will
	no longer respond when a new frame is generated.

	@param [in] pListener Pointer to a listener to remove.

	@see @ref UserTracker::NewFrameListener for more information on using event based interaction with UserTracker.
	*/
	void removeNewFrameListener(NewFrameListener* pListener)
	{
		niteUnregisterUserTrackerCallbacks(m_userTrackerHandle, &pListener->getCallbacks());
		pListener->setUserTracker(NULL);
	}

	/**
	In general, two coordinate systems are used in OpenNI 2.0.  These conventions are also followed in NiTE 2.0.

	Skeleton joint positions are provided in "Real World" coordinates, while the native coordinate system of depth maps is the "projective"
	system.  In short, "Real World" coordinates locate objects using a Cartesian coordinate system with the origin at the sensor.  "Projective"
	coordinates measure straight line distance from the sensor (perpendicular to the sensor face), and indicate x/y coordinates
	using pixels in the image (which is mathematically equivalent to specifying angles).  See the OpenNI 2.0 documentation online for more information.

	Note that no output is given for the Z coordinate.  Z coordinates remain the same when performing the conversion.  An input value is
	still required for Z, since this can affect the x/y output.

	This function allows you to convert the coordinates of a SkeletonJoint to the native coordinates of a depth map.  This is useful
	if you need to find the joint position on the raw depth map.

	@param [in] x The input X coordinate using the "real world" coordinate system.
	@param [in] y The input Y coordinate using the "real world" coordinate system.
	@param [in] z The input Z coordinate using the "real world" coordinate system.
	@param [out] pOutX Pointer to a location to store the output X coordinate in the "projective" system.
	@param [out] pOutY Pointer to a location to store the output Y coordinate in the "projective" system.
	@returns @ref Status indicating success or failure of this operation.  This is needed because the ability to
	convert between coordinate systems requires a properly initalized Device from OpenNI 2.0.
	*/
	Status convertJointCoordinatesToDepth(float x, float y, float z, float* pOutX, float* pOutY) const
	{
		return (Status)niteConvertJointCoordinatesToDepth(m_userTrackerHandle, x, y, z, pOutX, pOutY);
	}

	/**
	In general, two coordinate systems are used in OpenNI 2.0.  These conventions are also followed in NiTE 2.0.

	Skeleton joint positions are provided in "Real World" coordinates, while the native coordinate system of depth maps is the "projective"
	system.  In short, "Real World" coordinates locate objects using a Cartesian coordinate system with the origin at the sensor.  "Projective"
	coordinates measure straight line distance from the sensor, and indicate x/y coordinates using pixels in the image (which is mathematically
	equivalent to specifying angles).  See the OpenNI 2.0 documentation online for more information.

	This function allows you to convert the native depth map coordinates to the system used by the joints.  This might be useful for
	performing certain types of measurements (eg distance between a joint and an object identified only in the depth map).

	Note that no output is given for the Z coordinate.  Z coordinates remain the same when performing the conversion.  An input value is
	still required for Z, since this can affect the x/y output.

	@param [in] x The input X coordinate using the "projective" coordinate system.
	@param [in] y The input Y coordinate using the "projective" coordinate system.
	@param [in] z The input Z coordinate using the "projective" coordinate system.
	@param [out] pOutX Pointer to a location to store the output X coordinate in the "real world" system.
	@param [out] pOutY Pointer to a location to store the output Y coordinate in the "real world" system.
	@returns @ref Status indicating success or failure of this operation.  This is needed because the ability to
	convert between coordinate systems requires a properly initalized Device from OpenNI 2.0.
	*/
	Status convertDepthCoordinatesToJoint(int x, int y, int z, float* pOutX, float* pOutY) const
	{
		return (Status)niteConvertDepthCoordinatesToJoint(m_userTrackerHandle, x, y, z, pOutX, pOutY);
	}

private:
	NiteUserTrackerHandle m_userTrackerHandle;
};
